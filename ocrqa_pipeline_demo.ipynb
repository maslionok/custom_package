{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# OCR QA Score Pipeline with Impresso Package"
      ],
      "metadata": {
        "id": "rhQe5f0yBLS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is this notebook about?\n",
        "\n",
        "This notebook demonstrates the functionality and use cases of the Impresso subpackage `ocrqa`.\n",
        "\n",
        "At its core, this package/pipeline takes a text input and calculates a QA score using a Bloom filter. It first automatically detects the language of the text using the Impresso subpackage `langident` (unless explicitly specified). The pipeline dynamically checks all available languages based on existing Bloom filters and returns an \"unsupported language\" message if the language is not yet available. If supported, it retrieves the latest Bloom filter for the detected language from the Impresso Hugging Face repository: `impresso-project/OCR-quality-assessment-unigram`, which is then used to calculate the QA score.\n",
        "\n",
        "*  QA Score: A value between 0 and 1, representing the ratio of known to unknown words in the text compared to the Bloom filter.\n",
        "\n",
        "Additionally, as will be shown below, the pipeline provides optional arguments that allow for more advanced usage of the package.\n",
        "\n"
      ],
      "metadata": {
        "id": "2oEACNWrBUFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prerequisites"
      ],
      "metadata": {
        "id": "dyx4fqlXBXEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, you should install Impresso package:"
      ],
      "metadata": {
        "id": "q891fk9XFHay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install glebs_package"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "S2_e-lIOFMRN",
        "outputId": "38a9bcd0-f59f-4521-d91a-ae1c79fd7181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting glebs_package\n",
            "  Downloading glebs_package-1.2.2-py3-none-any.whl.metadata (351 bytes)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from glebs_package) (3.0.12)\n",
            "Collecting pybloomfiltermmap3 (from glebs_package)\n",
            "  Downloading pybloomfiltermmap3-0.6.0.tar.gz (505 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.3/505.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from glebs_package) (0.28.1)\n",
            "Collecting floret (from glebs_package)\n",
            "  Downloading floret-0.10.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from floret->glebs_package) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->glebs_package) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->glebs_package) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->glebs_package) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->glebs_package) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->glebs_package) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->glebs_package) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->glebs_package) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->glebs_package) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->glebs_package) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->glebs_package) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->glebs_package) (2025.1.31)\n",
            "Downloading glebs_package-1.2.2-py3-none-any.whl (5.1 kB)\n",
            "Downloading floret-0.10.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.6/321.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pybloomfiltermmap3\n",
            "  Building wheel for pybloomfiltermmap3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybloomfiltermmap3: filename=pybloomfiltermmap3-0.6.0-cp311-cp311-linux_x86_64.whl size=430645 sha256=1cb8dd6cb947b0e65f7bb7d7b38f6a484bf72f7fdf7af20f7cef167b652c2c28\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/d3/6e/7dd6b4a7c9d40160ab13b243b85162c2ba42503d9f3efc6afa\n",
            "Successfully built pybloomfiltermmap3\n",
            "Installing collected packages: pybloomfiltermmap3, floret, glebs_package\n",
            "Successfully installed floret-0.10.5 glebs_package-1.2.2 pybloomfiltermmap3-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Basic Usage"
      ],
      "metadata": {
        "id": "nHEncypABbeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unless explicitly specified, the pipeline uses the Impresso subpackage `langident` to detect the language of the text with the latest available model. For more details on the langident subpackage, please refer to the Impresso demo notebook *langident_pipeline_demo.ipynb*.\n",
        "\n",
        "Once the language is detected, the pipeline checks if a corresponding Bloom filter exists. If available, it retrieves and uses the latest version."
      ],
      "metadata": {
        "id": "bD5nkNwuFsH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start by importing the necessary module from Impresso package\n",
        "from glebs_package.ocrqa import OCRQAPipeline\n",
        "ocrqa_pipeline = OCRQAPipeline()"
      ],
      "metadata": {
        "id": "NVi5bRsaFdLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you initialize the pipeline, you can simply provide the text you'd like to classify. This example demonstrates the use of German text."
      ],
      "metadata": {
        "id": "V9NbNk_THMER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "de_text = \"Ein kleiner Hund namens Max lebte in einem ruhigen Dorf. Jeden Tag rannte er durch die Straßen und spielte mit den Kindern. Eines Tages fand er einen geheimen Garten, den niemand kannte. Max entschied sich, den Garten zu erkunden und entdeckte viele schöne Blumen und Tiere. Von diesem Tag an besuchte er den Garten jeden Nachmittag.\""
      ],
      "metadata": {
        "id": "ycZz3bjwHEPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ocrqa_pipeline(de_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DebXqYB0HRtM",
        "outputId": "400662ee-4f70-43f8-f427-dadac63d6c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'language': 'de', 'score': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The default output of the pipeline is a dictionary containing the detected language and the corresponding QA score. The QA score is rounded to one decimal place to account for minor variations, such as the presence of unusual names, which should not significantly impact the overall score.\n",
        "\n",
        "In this example, the score is 1.0, indicating that almost all words in the text exist in the Bloom filter. This suggests that the OCR process was highly successful."
      ],
      "metadata": {
        "id": "OlmUZvxIHaVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Advanced Usage"
      ],
      "metadata": {
        "id": "LT0z6ugxBdF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This pipeline offers several additional attributes that can be used when calling it to gain a deeper understanding of the results. These attributes include `language`, `version`, `diagnostics`, `model_id`, and `supported_languages`:\n",
        "\n",
        "*   `language`: Accepts language abbreviation strings such as \"en\" (English) or \"de\" (German). If provided, the pipeline assumes the specified language and skips the language detection step, directly using the corresponding Bloom filter.\n",
        "\n",
        "*   `version`: Accepts a specific Bloom filter model version in the format \"1.0.5\" or \"1.0.6\". If specified, the pipeline uses the requested version (if available) and skips the automatic retrieval of the latest model.\n",
        "\n",
        "*   `diagnostics`: Boolean. If set to True, the pipeline returns additional information, such as known_tokens, unknown_tokens, and the Bloom filter name used. For more details, see the sections below.\n",
        "\n",
        "*   `model_id`: Boolean. If set to True, the pipeline includes the name of the Bloom filter model used in the output.\n",
        "\n",
        "*   `supported_languages`: Boolean. If set to True, the pipeline returns a list of supported languages (i.e., languages for which a Bloom filter is available).\n",
        "\n",
        "These attributes can be used individually, in combination with each other, or all at once, depending on the level of detail needed."
      ],
      "metadata": {
        "id": "Y6iu4jelILoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1**: `language`"
      ],
      "metadata": {
        "id": "8qpBHjqvLMS2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9jmh60QA8Xx",
        "outputId": "3ab612d9-be29-4a04-e2f5-82fbf58571f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'language': 'lb', 'score': 0.9}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Using the same German text example as before\n",
        "ocrqa_pipeline(de_text, language=\"lb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though the provided text is clearly in German, specifying the language as Luxembourgish, for example, forces the pipeline to use the corresponding Bloom filter for that language. If the selected language is unsupported, the pipeline will return an appropriate error message."
      ],
      "metadata": {
        "id": "m6IfMkZpLpFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2**: `version`"
      ],
      "metadata": {
        "id": "1BCop6krMBkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the same German text example as before\n",
        "ocrqa_pipeline(de_text, version=\"1.0.5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_y6HMbrLS-c",
        "outputId": "af63205a-ad6e-4482-b715-527fb933364b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'language': 'de', 'score': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example above, by explicitly setting the `version` to *1.0.5* , you are instructing the pipeline to use the Bloom filter corresponding to this version, even if a more recent version is available."
      ],
      "metadata": {
        "id": "iIzkhKNqM8uP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 3**: `diagnostics`"
      ],
      "metadata": {
        "id": "NuHr1YDHNZGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the same German text example as before\n",
        "ocrqa_pipeline(de_text, diagnostics=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOSWx-rkMpvJ",
        "outputId": "1ac86d71-43a6-4ae2-f508-d9bab47c660f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'language': 'de',\n",
              " 'score': 1.0,\n",
              " 'diagnostics': {'known_tokens': ['jeden',\n",
              "   'die',\n",
              "   'lebte',\n",
              "   'eines',\n",
              "   'diesem',\n",
              "   'namens',\n",
              "   'einen',\n",
              "   'hund',\n",
              "   'er',\n",
              "   'entdeckte',\n",
              "   'von',\n",
              "   'straßen',\n",
              "   'den',\n",
              "   'besuchte',\n",
              "   'viele',\n",
              "   'zu',\n",
              "   'durch',\n",
              "   'tag',\n",
              "   'kleiner',\n",
              "   'fand',\n",
              "   'nachmittag',\n",
              "   'garten',\n",
              "   'sich',\n",
              "   'in',\n",
              "   'spielte',\n",
              "   'mit',\n",
              "   'tiere',\n",
              "   'an',\n",
              "   'entschied',\n",
              "   'rannte',\n",
              "   'tages',\n",
              "   'blumen',\n",
              "   'kindern',\n",
              "   'schöne',\n",
              "   'geheimen',\n",
              "   'einem',\n",
              "   'niemand',\n",
              "   'dorf',\n",
              "   'ruhigen',\n",
              "   'max',\n",
              "   'kannte',\n",
              "   'erkunden',\n",
              "   'und',\n",
              "   'ein'],\n",
              "  'unknowns_tokens': [],\n",
              "  'bloom_filter': 'ocrqa-wp_v1.0.6-de.bloom'}}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you set `diagnostics` to *True* , an additional key, `diagnostics`, will be added to the dictionary. The value of this key contains all known and unknown tokens, as well as the name of the Bloom filter used. In this example, we can see that there are no unknown words, meaning every word exists in this specific Bloom filter."
      ],
      "metadata": {
        "id": "bcbLziN_OwfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 4**: `model_id`"
      ],
      "metadata": {
        "id": "TAGVU8cGNfy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the same German text example as before\n",
        "ocrqa_pipeline(de_text, model_id=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FHAOX0QPati",
        "outputId": "49a3a748-b2e0-4c60-9e26-1edc278c51fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'language': 'de', 'score': 1.0, 'bloom_filter': 'ocrqa-wp_v1.0.6-de.bloom'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the `diagnostics` attribute, the `model_id` attribute is a simpler version. If set to `True`, the pipeline will return an additional key, `bloom_filter`, with the value indicating the Bloom filter that was used for the analysis."
      ],
      "metadata": {
        "id": "EzEnDhokPeeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 5**: `supported languages`"
      ],
      "metadata": {
        "id": "O3X0rNIeNgON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the same German text example as before\n",
        "ocrqa_pipeline(de_text, supported_languages=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7jkZAR2NlnF",
        "outputId": "92a74113-e3f2-4406-c3b6-192f74acc690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'language': 'de',\n",
              " 'score': 1.0,\n",
              " 'supported_languages': ['de', 'lb', 'fr', 'en']}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once `supported_languages` is set to *True*, the pipeline returns an additional key, `supported_languages`, with a value containing a list of all currently supported languages (i.e., languages that have a corresponding Bloom filter)."
      ],
      "metadata": {
        "id": "3xHzczRtP9_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 6**: All at once"
      ],
      "metadata": {
        "id": "_YLZAibuP1Jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the same German text example as before\n",
        "ocrqa_pipeline(de_text, language=\"fr\", version=\"1.0.5\", diagnostics=True, model_id=True, supported_languages=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKLHCUZ4P3OG",
        "outputId": "313f30cb-947b-47c2-a6c8-5c201e6cb6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'language': 'fr',\n",
              " 'score': 0.8,\n",
              " 'diagnostics': {'known_tokens': ['jeden',\n",
              "   'die',\n",
              "   'eines',\n",
              "   'diesem',\n",
              "   'namens',\n",
              "   'einen',\n",
              "   'hund',\n",
              "   'er',\n",
              "   'von',\n",
              "   'straßen',\n",
              "   'den',\n",
              "   'viele',\n",
              "   'zu',\n",
              "   'durch',\n",
              "   'tag',\n",
              "   'kleiner',\n",
              "   'fand',\n",
              "   'nachmittag',\n",
              "   'garten',\n",
              "   'sich',\n",
              "   'in',\n",
              "   'mit',\n",
              "   'tiere',\n",
              "   'an',\n",
              "   'tages',\n",
              "   'blumen',\n",
              "   'kindern',\n",
              "   'schöne',\n",
              "   'geheimen',\n",
              "   'einem',\n",
              "   'niemand',\n",
              "   'dorf',\n",
              "   'max',\n",
              "   'kannte',\n",
              "   'und',\n",
              "   'ein'],\n",
              "  'unknowns_tokens': ['lebte',\n",
              "   'ruhigen',\n",
              "   'entschied',\n",
              "   'rannte',\n",
              "   'erkunden',\n",
              "   'entdeckte',\n",
              "   'spielte',\n",
              "   'besuchte'],\n",
              "  'bloom_filter': 'ocrqa-wp_v1.0.5-fr.bloom'},\n",
              " 'supported_languages': ['de', 'lb', 'fr', 'en']}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use a mix of additional parameters, or all of them at once, to gain a deeper understanding of your QA score. In the example above, we set the language to French, which results in many unknown tokens being identified, as the Bloom filter used may not cover certain French words."
      ],
      "metadata": {
        "id": "xoA2pr-XQgMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Edge cases"
      ],
      "metadata": {
        "id": "He5YuZ_nR350"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "short_de_text_with_unusual_name = \"Glebs geht ins Büro.\""
      ],
      "metadata": {
        "id": "vvSzfgE2Qcvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Very short sentence\n",
        "ocrqa_pipeline(short_de_text_with_unusual_name, diagnostics=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-V1gu0MSHLG",
        "outputId": "5e39fdfd-217f-4f40-f14a-2b8b74546bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'language': 'lb',\n",
              " 'score': 0.8,\n",
              " 'diagnostics': {'known_tokens': ['ins', 'büro', 'geht'],\n",
              "  'unknowns_tokens': ['glebs'],\n",
              "  'bloom_filter': 'ocrqa-wp_v1.0.5-lb.bloom'}}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GEA0HPQKSJeg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}